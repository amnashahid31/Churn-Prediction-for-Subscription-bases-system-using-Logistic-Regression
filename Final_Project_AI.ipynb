{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Mounting Drive to Access the Dataset**\n",
        "(Done By: Amna Shahid - Team AI)"
      ],
      "metadata": {
        "id": "7Rgyh_7byS0e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8KNkIx0sDsi",
        "outputId": "390ce9cf-4d76-4db9-fff9-183650e1698a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Libraries**"
      ],
      "metadata": {
        "id": "fUKPLLhwyeV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing required libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler"
      ],
      "metadata": {
        "id": "ONY7uAp9x-Eb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Pre-Processing**"
      ],
      "metadata": {
        "id": "e6jsH6nzymip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset from drive\n",
        "df = pd.read_csv('/content/drive/MyDrive/AI Fellowship/train.csv')"
      ],
      "metadata": {
        "id": "bDApRC9FyLlL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling missing values\n",
        "# checking for missing values in the columns\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# filling missing values with 'median' in numerical columns\n",
        "num_cols = ['AccountAge', 'MonthlyCharges', 'TotalCharges', 'ViewingHoursPerWeek',\n",
        "                     'AverageViewingDuration', 'ContentDownloadsPerMonth', 'UserRating',\n",
        "                     'SupportTicketsPerMonth', 'WatchlistSize']\n",
        "\n",
        "df[num_cols] = df[num_cols].fillna(df[num_cols].median())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqI-TxOTzDHJ",
        "outputId": "db95d522-3008-435c-b039-fb6cc1d07210"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AccountAge                  0\n",
            "MonthlyCharges              0\n",
            "TotalCharges                0\n",
            "SubscriptionType            0\n",
            "PaymentMethod               0\n",
            "PaperlessBilling            0\n",
            "ContentType                 0\n",
            "MultiDeviceAccess           0\n",
            "DeviceRegistered            0\n",
            "ViewingHoursPerWeek         0\n",
            "AverageViewingDuration      0\n",
            "ContentDownloadsPerMonth    0\n",
            "GenrePreference             0\n",
            "UserRating                  0\n",
            "SupportTicketsPerMonth      0\n",
            "Gender                      0\n",
            "WatchlistSize               0\n",
            "ParentalControl             0\n",
            "SubtitlesEnabled            0\n",
            "CustomerID                  0\n",
            "Churn                       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding variables to have numerical values\n",
        "bin_cols = ['PaperlessBilling', 'MultiDeviceAccess', 'ParentalControl', 'SubtitlesEnabled']\n",
        "for col in bin_cols:\n",
        "    df[col] = df[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "\n",
        "encode_labels = LabelEncoder()\n",
        "categorical_columns = ['SubscriptionType', 'PaymentMethod', 'ContentType', 'DeviceRegistered',\n",
        "                       'GenrePreference', 'Gender']\n",
        "\n",
        "for col in categorical_columns:\n",
        "    df[col] = encode_labels.fit_transform(df[col])"
      ],
      "metadata": {
        "id": "JuG-6o17zWNh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling numerical features for standardization (to remove median values and make a standard unit value)\n",
        "scale = StandardScaler()\n",
        "df[num_cols] = scale.fit_transform(df[num_cols])"
      ],
      "metadata": {
        "id": "jQRVX3pzzhjh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into features (x) and target variable (y)\n",
        "X = df.drop(['CustomerID', 'Churn'], axis=1)\n",
        "y = df['Churn']"
      ],
      "metadata": {
        "id": "JZap4qyszpri"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# displaying training and testing sets\n",
        "print(f\"Training set size: {X_train.shape}\")\n",
        "print(f\"Test set size: {X_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnSXDGOKtRN0",
        "outputId": "b1678e1b-2d02-48d0-817f-900c761ccd9b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: (195029, 19)\n",
            "Test set size: (48758, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression Model Training** (For churn prediction for Subscription-Based Services)"
      ],
      "metadata": {
        "id": "k6HlMlvpz099"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "eAU9QEEx0J-s"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialization\n",
        "logreg = LogisticRegression(random_state=42)\n",
        "\n",
        "# Model Training\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Test dataset Prediction\n",
        "y_pred = logreg.predict(X_test)"
      ],
      "metadata": {
        "id": "OrUM5QzE1PyV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Preformance Evaluation\n",
        "# Model Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.3f}\")  # for upto 3 values after decimal\n",
        "\n",
        "# Model Confusion matrix (to tell how many overall predictions were correct)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Model Precision, Recall, F1-Score\n",
        "precision = precision_score(y_test, y_pred, average='binary')\n",
        "recall = recall_score(y_test, y_pred, average='binary')\n",
        "f1 = f1_score(y_test, y_pred, average='binary')\n",
        "\n",
        "# Print the results\n",
        "print(f\"Precision: {precision:.3f}\")\n",
        "print(f\"Recall: {recall:.3f}\")\n",
        "print(f\"F1-Score: {f1:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLjaUet1u5zU",
        "outputId": "b67d44a5-0400-41bc-e63c-3b9200de5b68"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.824\n",
            "Confusion Matrix:\n",
            "[[39188   780]\n",
            " [ 7788  1002]]\n",
            "Precision: 0.562\n",
            "Recall: 0.114\n",
            "F1-Score: 0.190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Uploading Model to be used as API**"
      ],
      "metadata": {
        "id": "pRSK1GwnTeUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained logistic regression model to a file\n",
        "joblib.dump(logreg, 'logreg.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSgF0zk2TRxR",
        "outputId": "ca186af1-c87a-4416-a82d-109b636ec7d4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['logreg.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}